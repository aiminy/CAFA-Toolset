#!/usr/bin/env python

import os
import sys
import argparse
import shutil
import subprocess
from os.path import basename 
from collections import defaultdict
from Bio.UniProt import GOA

import ArgParser_Benchmark as ap
import Config
import CreateBenchmark as cb
import FindDataset as fd
import FormatChecker as fc
import GOAParser_cafa as gc
import PaperTermFrequency as ptf

'''
   Benchmark program accepts 2 uniprot-goa gaf-format files as inputs. These 
   are available for download at ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/

   There are a host of other parameters that could be provided to filter 
   results. The list of all parameters can be obtained through the following 
   command:

   python Benchmark --help

   Running this program creates SIX benchmark files: THREE limited-knolwedge 
   (LK) files - one in each of the three ontolgies (MFO, BPO, and CCO) and 
   THREE no-knowledge (NK) files - one in each ontology.
'''

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

config_filename = '.cafarc' # default configuration file name

class Benchmark:
    def __init__(self, parser, ConfigParam):
        self.ConfigParam = ConfigParam
        self.parsed_dict = ap.parse(parser, self.ConfigParam)
                        # Get the user given parameters as a dictionary
        t1 = self.parsed_dict['t1'] # Retreive file name at time t1
        t2 = self.parsed_dict['t2'] # Retreive file name at time t2
        if self.parsed_dict['t1'] == self.parsed_dict['t2']:
            print 'Both input files are from the same time point. This will not create a valid benchmark set.'
            print 'Program quiting ...'
            sys.exit(1)

        outfile_basename = basename(self.parsed_dict['outfile']) 
                                   # Retreive output file name
        self.work_dir = (self.ConfigParam['workdir']).rstrip('/')
                                   # Retreive work directory name 
        if not os.path.exists(self.work_dir):
            os.makedirs(self.work_dir)
                # Create work direcoty, if it does not exist 

        self.t1_input_file = fd.find_dataset(t1, self.work_dir, 
                            self.ConfigParam) # Locate t1 file
        self.t2_input_file = fd.find_dataset(t2, self.work_dir, 
                            self.ConfigParam) # Locate t2 file

        # Names for SIX ouput files: bpo, cco, and mfo for LK and NK benchmark types:
        self.output_filename_LK_bpo = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'LK_bpo')
        self.output_filename_LK_cco = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'LK_cco')
        self.output_filename_LK_mfo = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'LK_mfo')
        self.output_filename_NK_bpo = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'NK_bpo')
        self.output_filename_NK_cco = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'NK_cco')
        self.output_filename_NK_mfo = self.create_output(self.parsed_dict, 
                                    outfile_basename, self.t2_input_file, 
                                    self.work_dir, 'NK_mfo')

        # Names for THREE files to store non-EXP and EXP type entries:
        # These files will be deleted once the calculation is done
        self.t1_iea_name = self.t1_input_file + '.iea'
                # File name for entries in t1 file with non-EXP evidence codes
        self.t1_exp_name = self.t1_input_file + '.exp'
                # File name for entries in t1 file with EXP evidence codes
        self.t2_exp_name = self.t2_input_file + '.exp'
                # File name for entries in t2 file with EXP evidence codes

        # Name for GO ID frequency per pubmed id for t2 file:
        # This file will be deleted once the calculations are done
        self.t2_ptf_file =  self.t2_input_file + '_with_annotations_per_paper.txt'
        
        # Names for SIX intermediate benchmark files:
        self.filename_LK_bpo = self.t2_exp_name + '.bpo_LK_bench.txt'
        self.filename_LK_cco = self.t2_exp_name + '.cco_LK_bench.txt'
        self.filename_LK_mfo = self.t2_exp_name + '.mfo_LK_bench.txt'
        self.filename_NK_bpo = self.t2_exp_name + '.bpo_NK_bench.txt'
        self.filename_NK_cco = self.t2_exp_name + '.cco_NK_bench.txt'
        self.filename_NK_mfo = self.t2_exp_name + '.mfo_NK_bench.txt'

    def create_output(self, params, outfile, infile, work_dir, ontType):
        # Creates an output filename based on the output file prefix 
        # provided by the user
        if not outfile == '':
            ob = basename(params['outfile'])
        else:
            if ontType == '':
                ob = basename(infile + '.benchmark')
            else: 
                ob = basename(infile + '.benchmark' + '_' + ontType)
        index = 1
        while os.path.exists(work_dir + '/' + ob + '.' + str(index)):
            index = index + 1
        output_filename = work_dir + '/' + ob + '.' + str(index)
        return output_filename

    def create_iterator(self, infile):
        # Returns an iterator object for an input uniprot-goa file along with a 
        # list of all field names contained in the uniprot-goa file

        infile_handle = open(infile, 'r')
        iter_handle = GOA.gafiterator(infile_handle)
        for ingen in iter_handle:
            if len(ingen) == 17:
                GAFFIELDS = GOA.GAF20FIELDS
                break
            else:
                GAFFIELDS = GOA.GAF10FIELDS
                break
        infile_handle = open(infile, 'r')
        iter_handle = GOA.gafiterator(infile_handle)
        return iter_handle, GAFFIELDS

    def remove_redundant_benchmarks(self):
        if os.stat(self.filename_LK_bpo).st_size == 0:
            print 'Your benchmark set for Biological Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_LK_bpo + \
                    " | sort | uniq " + " > " + self.output_filename_LK_bpo
            subprocess.call(cmd, shell=True)

        if os.stat(self.filename_LK_cco).st_size == 0:
            print 'Your benchmark set for Cellular Component Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_LK_cco + \
                    " | sort | uniq " + " > " + self.output_filename_LK_cco
            subprocess.call(cmd, shell=True)

        if os.stat(self.filename_LK_mfo).st_size == 0:
            print 'Your benchmark set for Molecular Function Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_LK_mfo + \
                    " | sort | uniq " + " > " + self.output_filename_LK_mfo
            subprocess.call(cmd, shell=True)

        if os.stat(self.filename_NK_bpo).st_size == 0:
            print 'Your no-knowledge benchmark set for Biological Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_NK_bpo + \
                    " | sort | uniq " + " > " + self.output_filename_NK_bpo
            subprocess.call(cmd, shell=True)

        if os.stat(self.filename_NK_cco).st_size == 0:
            print 'Your no-knowledge benchmark set for Cellular Component Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_NK_cco + \
                    " | sort | uniq " + " > " + self.output_filename_NK_cco
            subprocess.call(cmd, shell=True)

        if os.stat(self.filename_NK_mfo).st_size == 0:
            print 'Your no-knowledge benchmark set for Molecular Function Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.filename_NK_mfo + \
                    " | sort | uniq " + " > " + self.output_filename_NK_mfo
            subprocess.call(cmd, shell=True)
        return None

    def create_intermediate_files(self):
        # Create paper-term freq file for t2 file:
        ann_conf = ptf.paper_term_freq( open(self.t2_input_file,'r'), 
                                        open(self.t2_ptf_file,'w'), 
                                        self.parsed_dict)
#        print ann_conf.keys()
#        print ann_conf.values()
#        raise SystemExit
        # Create an iterator object for filtering t2 file:
        iter_handle, GAFFIELDS = self.create_iterator(self.t2_input_file)

        # Create tax_id_name_mapping for filtering t2 file:
        tax_id_name_mapping = gc.parse_tax_file(self.ConfigParam['tax_file'])

        # Create t2_exp_name file:
        # Filter t2 file for all proteins with EXP evidence:
        print 'Parsing t2 file: ' + basename(self.t2_input_file) + ' ...'
        t2_exp_handle = open(self.t2_exp_name, 'w')
        for ingen in iter_handle: # Iterate through t2 file entries
            retval = gc.record_has_forBenchmark(ingen, 
                                                ann_conf, 
                                                self.parsed_dict,
                                                tax_id_name_mapping, 
                                                self.ConfigParam['exp_eec'], 
                                                GAFFIELDS)
            if retval: # If retval is TRUE, write out the record to t2.exp file 
                GOA.writerec(ingen, t2_exp_handle, GAFFIELDS) # Create t2.exp file
        t2_exp_handle.close()

        if os.stat(self.t2_exp_name).st_size == 0: # If t2.exp is empty, program quits
            print 'Your benchmark set will be empty with the parameters provided. Quiting ...'
            sys.exit(1)
       
        # Create t1.iea_name and t1.exp_name files: 
        # Filter t1 file to create t1.iea and t1.exp files
        iter_handle, GAFFIELDS = self.create_iterator(self.t1_input_file)
        print 'Parsing t1 file: ' + basename(self.t1_input_file) + ' ...' 
        gc.t1_filter(iter_handle, self.t1_iea_name, self.t1_exp_name, 
                    self.t2_exp_name, GAFFIELDS, self.ConfigParam['exp_eec'])
        return None 

    def delete_intermediate_files(self):
        print 'Cleaning working directory ...'
        # Delete SIX intermediate benchmark files: 
        os.remove(self.filename_LK_bpo)
        os.remove(self.filename_LK_cco)
        os.remove(self.filename_LK_mfo)
        os.remove(self.filename_NK_bpo)
        os.remove(self.filename_NK_cco)
        os.remove(self.filename_NK_mfo)
        # Delete t1.iea, t1.exp, and t2.exp files: 
        os.remove(self.t1_iea_name)
        os.remove(self.t1_exp_name)
        os.remove(self.t2_exp_name)
        # Delete paper term frequency file for t2 file:
#        os.remove(self.t2_ptf_file)
        # Delete any empty files from the workspace (subdirectories included):
        for root, dirs, files in os.walk(self.work_dir):
            for fname in files:
                if os.path.getsize(root + '/' + fname) == 0:
                    os.remove(root + '/' + fname)
            break
        return None

    def print_epilog(self):
        print bcolors.OKGREEN + 'The following benchmark files are created:' + bcolors.ENDC 
        if os.path.exists(self.output_filename_LK_bpo):
            print basename(self.output_filename_LK_bpo)
        if os.path.exists(self.output_filename_LK_cco):
            print basename(self.output_filename_LK_cco)
        if os.path.exists(self.output_filename_LK_mfo):
            print basename(self.output_filename_LK_mfo)
        if os.path.exists(self.output_filename_NK_bpo):
            print basename(self.output_filename_NK_bpo)
        if os.path.exists(self.output_filename_NK_cco):
            print basename(self.output_filename_NK_cco)
        if os.path.exists(self.output_filename_NK_mfo):
            print basename(self.output_filename_NK_mfo)
        print bcolors.OKGREEN + 'Thank you for using Benchmark Creation Tool' + bcolors.ENDC
        return None

    def process_data(self): # Process user data and create benchmark sets
        fc.check_gaf_format(self.t1_input_file) # File format check for t1 file
        fc.check_gaf_format(self.t2_input_file) # File format check for t2 file
        self.create_intermediate_files() # Create necessary intermediate files
        cb.create_benchmarks(self.t1_iea_name,
                             self.t1_exp_name,
                             self.t2_exp_name) # Create SIX benchmark sets
        self.remove_redundant_benchmarks() # Remove redundant benchmark entries
        self.delete_intermediate_files() # Remove intermediate files
        self.print_epilog() # Print summary of running this program
        return None

if __name__ == '__main__': 
    parser = ap.parse_argument() # Collect input arguments
    ConfigParam = Config.read_config(config_filename) # Collect config entries
    bm = Benchmark(parser, ConfigParam) # Create a Benchmark instance 
    bm.process_data() # Process data and create benchmark sets
