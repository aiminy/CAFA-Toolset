#!/usr/bin/env python

import os
import sys
import argparse
import shutil
import subprocess
from os.path import basename 

from Bio.UniProt import GOA

import ArgParser_Benchmark as ap
import Config
import CreateDataset as cd
import FilterBenchmark as fb
import FormatChecker as fc
import GOAParser_cafa as gc
import PaperTermFrequency as ptf

'''
   Benchmark program accepts 2 uniprot-goa gaf-format files as inputs. These 
   are available for download at ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/

   There are a host of other parameters that could be provided to filter 
   results. The list of all parameters can be obtained through the following 
   command:

   python Benchmark --help

   Running this program creates SIX benchmark files: THREE limited-knolwedge 
   (LK) files - one in each of the three ontolgies (MFO, BPO, and CCO) and 
   THREE no-knowledge (NK) files - one in each ontology.
'''

config_filename='.cafarc' # default configuration file name
class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def create_output(params, outfile, infile, work_dir, ontType):
    # Creates an output filename based on the output file prefix 
    # provided by the user
    if not outfile == '':
        ob = basename(params['outfile'])
    else:
        if ontType == '':
            ob = basename(infile + '.benchmark')
        else: 
            ob = basename(infile + '.benchmark' + '_' + ontType)
    index = 1
    while os.path.exists(work_dir + '/' + ob + '.' + str(index)):
        index = index + 1
    output_filename = ob + '.' + str(index)
    return output_filename

def create_iterator(infile):
    # Returns an iterator object for an input uniprot-goa file along with a 
    # list of all field names contained in the uniprot-goa file

    infile_handle = open(infile, 'r')
    iter_handle = GOA.gafiterator(infile_handle)
    for ingen in iter_handle:
        if len(ingen) == 17:
            GAFFIELDS = GOA.GAF20FIELDS
            break
        else:
            GAFFIELDS = GOA.GAF10FIELDS
            break
    infile_handle = open(infile, 'r')
    iter_handle = GOA.gafiterator(infile_handle)
    return iter_handle, GAFFIELDS

def paper_term_freq(params, infile):
    # Given an input uniprot-goa file, this method computes the number of 
    # proteins annotated in every pubmed id mentioned in that file
    if params['Confidence'] == 'T':
        paper_threshold = params['Threshold']
        ann_conf_filter = True
    else:
        ann_conf_filter = False
        paper_threshold = 0
    if not os.path.exists(infile + '_with_annotations_per_paper.txt'):
        paper_annotation_freq  = infile + '_with_annotations_per_paper.txt'
        paper_conf_filter = True
        paper_ann_freq_handle = open(paper_annotation_freq, 'w')
    else:
        paper_conf_filter = False
    
    if ann_conf_filter or paper_conf_filter:
        [ann_conf, paper_conf] = ptf.count(infile, params['Evidence'], 
                                                          ann_conf_filter, paper_conf_filter)
        if len(paper_conf) > 0:
            for i in paper_conf:
                print >> paper_ann_freq_handle, i + '\t' + str(len(paper_conf[i]))

            paper_conf.clear()
    else:
        ann_conf = defaultdict(lambda:defaultdict(set))
    return ann_conf

parser = ap.parse_argument()
ConfigParam = Config.read_config(config_filename)

work_dir = ConfigParam['workdir']
work_dir = work_dir.rstrip('/')
uniprot_path = ConfigParam['uniprot_path'] .rstrip('/')

# In case the working directory is not found, the program will create one in this step
if not os.path.exists(work_dir):
    os.makedirs(work_dir)

# Parses the set of user given parameters and returns a dictionary of the same.
parsed_dict = ap.parse(parser, ConfigParam)
t1 = parsed_dict['t1']
t2 = parsed_dict['t2']
outfile_basename = basename(parsed_dict['outfile'])

# Create input datasets based on whether the user chose CAFA or non-CAFA mode 
if parsed_dict['t1'] == parsed_dict['t2']:
    print 'Both input files are from the same time point. This will not create a valid benchmark set.'
    print 'Program quiting ...'
    sys.exit(1)

t1_input_file = work_dir + '/' + cd.parse(t1, ConfigParam) # Parse t1 file.
t2_input_file = work_dir + '/' + cd.parse(t2, ConfigParam) # parse t2 file.

# Filename initialization
output_filename_LK_bpo = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'LK_bpo')
output_filename_LK_cco = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'LK_cco')
output_filename_LK_mfo = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'LK_mfo')
output_filename_NK_bpo = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'NK_bpo')
output_filename_NK_cco = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'NK_cco')
output_filename_NK_mfo = work_dir + '/' + create_output(
    parsed_dict, outfile_basename, t2_input_file, work_dir, 'NK_mfo')

t1_iea_name = t1_input_file + '.iea' 
      # This file will be used for recording entries in t1 file with 
      # non-experimental evidence codes
t1_exp_name = t1_input_file + '.exp'
      # This file will be used for recording entries in t1 file with 
      # experimental evidence codes
t2_exp_name = t2_input_file + '.exp'
      # This file will be used for recording entries in t2 file 
      # with experimental evidence codes

filename_LK_bpo = t2_exp_name + '.bpo_LK_bench.txt'
filename_LK_cco = t2_exp_name + '.cco_LK_bench.txt'
filename_LK_mfo = t2_exp_name + '.mfo_LK_bench.txt'
filename_NK_bpo = t2_exp_name + '.bpo_NK_bench.txt'
filename_NK_cco = t2_exp_name + '.cco_NK_bench.txt'
filename_NK_mfo = t2_exp_name + '.mfo_NK_bench.txt'

fc.check_gaf_format(t1_input_file) # Format checker module for input file t1
fc.check_gaf_format(t2_input_file) # Format checker module for input file t2

# Create paper-term frequency file
ann_conf = paper_term_freq(parsed_dict, t2_input_file)

# Creates an iterator object for t2 file
iter_handle, GAFFIELDS = create_iterator(t2_input_file)

# Creates a dictionary of taxon id-name mapping
tax_id_name_mapping = gc.parse_tax_file(ConfigParam['tax_file'])

# Filters t2 file for all proteins with experimentally annotated terms
# based on user defined parameters

print 'Parsing t2 file: ' + basename(t2_input_file) + ' ...'
t2_exp_handle = open(t2_exp_name, 'w')
for ingen in iter_handle: # iterate through t2 file
    retval = gc.record_has_forBenchmark(ingen,ann_conf, parsed_dict,
        tax_id_name_mapping, ConfigParam['exp_eec'], GAFFIELDS)
    if retval: # if retval is TRUE, write out the record to t2.exp file 
        GOA.writerec(ingen,t2_exp_handle,GAFFIELDS) # creates t2.exp file
t2_exp_handle.close()
    
# If t2.exp file is empty, it would end up producing an empty benchmark file. 
# To prevent this, the program will quit here with a message.
if os.stat(t2_exp_name).st_size == 0:
    print 'Your benchmark set will be empty with the parameters provided. Quiting ...'
    sys.exit(1)

# Filters t1 file and creates benchmark
iter_handle, GAFFIELDS = create_iterator(t1_input_file)
print 'Parsing t1 file: ' + basename(t1_input_file) + ' ...' 
gc.t1_filter(
    iter_handle, t1_iea_name, t1_exp_name, t2_exp_name, GAFFIELDS, ConfigParam['exp_eec'])
           # This methods creats the t1.iea and t1.exp files

print 'Creating benchmark set ...'
fb.filter_benchmarks(t1_iea_name, t1_exp_name, t2_exp_name) 
          # Filters benchmarks and create SIX benchmark files

#sd.down(output_filename, uniprot_path, unique_proteins)

# Checks the size of the benchmark files created in cb.filter_benchmark method.
# If any file is found to be empty, the program will print a message saying so. 
# Otherwise, it will remove the redundant entries in that file and create a 
# final benchmark file with unique benchmark entries. It will do so for each of
# the SIX benchmark files.
if os.stat(filename_LK_bpo).st_size == 0:
    print 'Your benchmark set for Biological Process Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_LK_bpo +  " | sort | uniq " + " > " + output_filename_LK_bpo
    subprocess.call(cmd, shell=True)

if os.stat(filename_LK_cco).st_size == 0:
    print 'Your benchmark set for Cellular Component Process Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_LK_cco +  " | sort | uniq " + " > " + output_filename_LK_cco
    subprocess.call(cmd, shell=True)

if os.stat(filename_LK_mfo).st_size == 0:
    print 'Your benchmark set for Molecular Function Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_LK_mfo +  " | sort | uniq " + " > " + output_filename_LK_mfo
    subprocess.call(cmd, shell=True)

if os.stat(filename_NK_bpo).st_size == 0:
    print 'Your no-knowledge benchmark set for Biological Process Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_NK_bpo +  " | sort | uniq " + " > " + output_filename_NK_bpo
    subprocess.call(cmd, shell=True)

if os.stat(filename_NK_cco).st_size == 0:
    print 'Your no-knowledge benchmark set for Cellular Component Process Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_NK_cco +  " | sort | uniq " + " > " + output_filename_NK_cco
    subprocess.call(cmd, shell=True)

if os.stat(filename_NK_mfo).st_size == 0:
    print 'Your no-knowledge benchmark set for Molecular Function Ontology is empty.'
else:
    cmd = "awk -F \'\t\' '{print;}' " + filename_NK_mfo +  " | sort | uniq " + " > " + output_filename_NK_mfo
    subprocess.call(cmd, shell=True)

# Cleans the working directory by removing files created in the 
# intermediate steps. These files include files for iea and exp from 
# t1 and t2 input files and filter benchmark files
print 'Cleaning working directory ...'
# Removing the temporary benchmark files created by fb.filter_benchmark() method
os.remove(filename_LK_bpo)
os.remove(filename_LK_cco)
os.remove(filename_LK_mfo)
os.remove(filename_NK_bpo)
os.remove(filename_NK_cco)
os.remove(filename_NK_mfo)
os.remove(t1_input_file + '.iea')
if os.path.exists(t1_input_file + '.exp'):
    os.remove(t1_input_file + '.exp')
os.remove(t2_exp_name)
os.remove(t2_input_file + '_with_annotations_per_paper.txt')
#Deletes all empty files from the working directory and its subdirectories
for root, dirs, files in os.walk(work_dir):
    for fname in files:
        if os.path.getsize(root + '/' + fname) == 0:
            os.remove(root + '/' + fname)
    break
print bcolors.OKGREEN + 'The following benchmark files are created:' + bcolors.ENDC 
if os.path.exists(output_filename_LK_bpo):
    print basename(output_filename_LK_bpo)
if os.path.exists(output_filename_LK_cco):
    print basename(output_filename_LK_cco)
if os.path.exists(output_filename_LK_mfo):
    print basename(output_filename_LK_mfo)
if os.path.exists(output_filename_NK_bpo):
    print basename(output_filename_NK_bpo)
if os.path.exists(output_filename_NK_cco):
    print basename(output_filename_NK_cco)
if os.path.exists(output_filename_NK_mfo):
    print basename(output_filename_NK_mfo)
print bcolors.OKGREEN + 'Thank you for using Benchmark Creation Tool' + bcolors.ENDC 
