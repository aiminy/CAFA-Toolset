#!/usr/bin/env python

import os
import sys
import argparse
import shutil
import subprocess
from os.path import basename 
from collections import defaultdict
from Bio.UniProt import GOA

import ArgParser_Benchmark as ap
import Config
import CreateBenchmark as cb
import FindDataset as fd
import FormatChecker as fc
import GOAParser_cafa as gc
import PaperTermFrequency as ptf

'''
   Benchmark program accepts two input files in uniprot-goa GAF format at 
   two distinct time pointst t1 and t2. The input files can be downloaded 
   from ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/. The simplest way to run 
   this program is: 

   python Benchmark -I1=input_file_at_t1 -I2=input_file_at_t2 

   Running this program creates SIX benchmark files: THREE limited-knolwedge 
   (LK) benchmark files - one in each of the three ontolgies (MFO, BPO, and 
   CCO) and THREE no-knowledge (NK) benchmark files - one in each ontology.
   
   Complete usage directions of this program can obtained through the 
   following command: 

   python Benchmark --help
'''

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

config_filename = '.cafarc' # Default configuration file name

class Benchmark:
    def __init__(self):
        self.parsed_dict = ap.parse_args('benchmark')
                        # Obtain user supplied argument values in a dictionary 
        self.ConfigParam = Config.read_config(config_filename) # Collect config file entries
        t1 = self.parsed_dict['t1'] # Retreive file name at time t1
        t2 = self.parsed_dict['t2'] # Retreive file name at time t2
        if self.parsed_dict['t1'] == self.parsed_dict['t2']:
            print 'Both input files are from the same time point.\
                This will not create a valid benchmark set.'
            print 'Program quiting ...'
            sys.exit(1)
        outfile_basename = basename(self.parsed_dict['outfile'])
                                   # Retreive output file name
        self.work_dir = (self.ConfigParam['workdir']).rstrip('/')
                                   # Retreive work directory name
        if not os.path.exists(self.work_dir):
            os.makedirs(self.work_dir)
                # Create work direcoty, if it does not exist
        self.t1_input_file = fd.find_dataset(t1, self.work_dir,
                            self.ConfigParam) # Locate t1 file
        self.t2_input_file = fd.find_dataset(t2, self.work_dir,
                            self.ConfigParam) # Locate t2 file

        # Names for SIX ouput files: bpo, cco, and mfo for LK and NK benchmark types:
        self.output_filename_LK_bpo = self.create_outfilename('LK_bpo')
        self.output_filename_LK_cco = self.create_outfilename('LK_cco')
        self.output_filename_LK_mfo = self.create_outfilename('LK_mfo')
        self.output_filename_NK_bpo = self.create_outfilename('NK_bpo')
        self.output_filename_NK_cco = self.create_outfilename('NK_cco')
        self.output_filename_NK_mfo = self.create_outfilename('NK_mfo')

        # Names for THREE files to store non-EXP and EXP type entries:
        # These files will be deleted once the calculation is done
        self.t1_iea_name = self.t1_input_file + '.iea'
                # File name for entries in t1 file with non-EXP evidence codes
        self.t1_exp_name = self.t1_input_file + '.exp'
                # File name for entries in t1 file with EXP evidence codes
        self.t2_exp_name = self.t2_input_file + '.exp'
                # File name for entries in t2 file with EXP evidence codes

        # Name for GO ID frequency per pubmed id for t2 file:
        # This file will be deleted once the calculations are done
        self.t2_ptf_file =  self.t2_input_file + '_with_annotations_per_paper.txt'
        
        # Names for SIX intermediate benchmark files:
        self.bmfile_LK_bpo = self.t2_exp_name + '.bpo_LK_bench.txt'
        self.bmfile_LK_cco = self.t2_exp_name + '.cco_LK_bench.txt'
        self.bmfile_LK_mfo = self.t2_exp_name + '.mfo_LK_bench.txt'
        self.bmfile_NK_bpo = self.t2_exp_name + '.bpo_NK_bench.txt'
        self.bmfile_NK_cco = self.t2_exp_name + '.cco_NK_bench.txt'
        self.bmfile_NK_mfo = self.t2_exp_name + '.mfo_NK_bench.txt'

    def create_outfilename(self, ontType):
        # Creates an output filename based on the output file prefix 
        # provided by the user
        if not self.parsed_dict['outfile'] == '':
            ob = basename(self.parsed_dict['outfile']) + '_' + ontType
        else:
            ob = basename(self.parsed_dict['t2']) + '-' + \
                ((basename(self.parsed_dict['t1'])).split('.'))[-1] + \
                '.benchmark' + '_' + ontType
        index = 1
        while os.path.exists(self.work_dir + '/' + ob + '.' + str(index)):
            index = index + 1
        output_filename = self.work_dir + '/' + ob + '.' + str(index)
        return output_filename

    def create_iterator(self, infile):
        # Returns an iterator object for an input uniprot-goa file along with a 
        # list of all field names contained in the uniprot-goa file

        infile_handle = open(infile, 'r')
        iter_handle = GOA.gafiterator(infile_handle)
        for ingen in iter_handle:
            if len(ingen) == 17:
                GAFFIELDS = GOA.GAF20FIELDS
                break
            else:
                GAFFIELDS = GOA.GAF10FIELDS
                break
        infile_handle = open(infile, 'r')
        iter_handle = GOA.gafiterator(infile_handle)
        return iter_handle, GAFFIELDS

    def remove_redundant_benchmarks(self):
        if os.stat(self.bmfile_LK_bpo).st_size == 0:
            print 'Your benchmark set for Biological Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_LK_bpo + \
                    " | sort | uniq " + " > " + self.output_filename_LK_bpo
            subprocess.call(cmd, shell=True)

        if os.stat(self.bmfile_LK_cco).st_size == 0:
            print 'Your benchmark set for Cellular Component Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_LK_cco + \
                    " | sort | uniq " + " > " + self.output_filename_LK_cco
            subprocess.call(cmd, shell=True)

        if os.stat(self.bmfile_LK_mfo).st_size == 0:
            print 'Your benchmark set for Molecular Function Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_LK_mfo + \
                    " | sort | uniq " + " > " + self.output_filename_LK_mfo
            subprocess.call(cmd, shell=True)

        if os.stat(self.bmfile_NK_bpo).st_size == 0:
            print 'Your no-knowledge benchmark set for Biological Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_NK_bpo + \
                    " | sort | uniq " + " > " + self.output_filename_NK_bpo
            subprocess.call(cmd, shell=True)

        if os.stat(self.bmfile_NK_cco).st_size == 0:
            print 'Your no-knowledge benchmark set for Cellular Component Process Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_NK_cco + \
                    " | sort | uniq " + " > " + self.output_filename_NK_cco
            subprocess.call(cmd, shell=True)

        if os.stat(self.bmfile_NK_mfo).st_size == 0:
            print 'Your no-knowledge benchmark set for Molecular Function Ontology is empty.'
        else:
            cmd = "awk -F \'\t\' '{print;}' " + self.bmfile_NK_mfo + \
                    " | sort | uniq " + " > " + self.output_filename_NK_mfo
            subprocess.call(cmd, shell=True)
        return None

    def create_intermediate_files(self):
        # Create paper-term freq file for t2 file:
        ann_conf = ptf.paper_term_freq( open(self.t2_input_file,'r'),
                                        open(self.t2_ptf_file,'w'),
                                        self.parsed_dict)
        # Create an iterator object for filtering t2 file:
        iter_handle, GAFFIELDS = self.create_iterator(self.t2_input_file)

        # Create tax_id_name_mapping for filtering t2 file:
        tax_id_name_mapping = gc.parse_tax_file(self.ConfigParam['tax_file'])

        # Create t2_exp_name file:
        # Filter t2 file for all proteins with EXP evidence:
        print 'Parsing t2 file: ' + basename(self.t2_input_file) + ' ...'
        t2_exp_handle = open(self.t2_exp_name, 'w')
        for ingen in iter_handle: # Iterate through t2 file entries
            retval = gc.record_has_forBenchmark(ingen,
                                                ann_conf,
                                                self.parsed_dict,
                                                tax_id_name_mapping,
                                                self.ConfigParam['exp_eec'],
                                                GAFFIELDS)
            if retval: # If retval is TRUE, write out the record to t2.exp file
                GOA.writerec(ingen, t2_exp_handle, GAFFIELDS) # Create t2.exp file
        t2_exp_handle.close()

        if os.stat(self.t2_exp_name).st_size == 0: # If t2.exp is empty, program quits
            print 'Your benchmark set will be empty with the parameters provided. Quiting ...'
            sys.exit(1)
       
        # Create t1.iea_name and t1.exp_name files: 
        # Filter t1 file to create t1.iea and t1.exp files
        iter_handle, GAFFIELDS = self.create_iterator(self.t1_input_file)
        print 'Parsing t1 file: ' + basename(self.t1_input_file) + ' ...' 
        gc.t1_filter(iter_handle, self.t1_iea_name, self.t1_exp_name, 
                    self.t2_exp_name, GAFFIELDS, self.ConfigParam['exp_eec'])
        return None 

    def delete_intermediate_files(self):
        print 'Cleaning working directory ...'
        # Delete SIX intermediate benchmark files: 
        os.remove(self.bmfile_LK_bpo)
        os.remove(self.bmfile_LK_cco)
        os.remove(self.bmfile_LK_mfo)
        os.remove(self.bmfile_NK_bpo)
        os.remove(self.bmfile_NK_cco)
        os.remove(self.bmfile_NK_mfo)
        # Delete t1.iea, t1.exp, and t2.exp files: 
        os.remove(self.t1_iea_name)
        os.remove(self.t1_exp_name)
        os.remove(self.t2_exp_name)
        # Delete paper term frequency file for t2 file:
        os.remove(self.t2_ptf_file)
        # Delete any empty files from the workspace (subdirectories included):
        for root, dirs, files in os.walk(self.work_dir):
            for fname in files:
                if os.path.getsize(root + '/' + fname) == 0:
                    os.remove(root + '/' + fname)
            break
        return None

    def print_prolog(self):
        print "*************************************************"
        print "Welcome to Benchmark Creation Tool !!!!!"
        print "*************************************************\n"
        print 'Following is a list of user supplied inputs:\n'
        for arg in self.parsed_dict:
            print arg + ': ' + str(self.parsed_dict[arg])
        print '*********************************************\n'
        return None

    def print_epilog(self):
        print bcolors.OKGREEN + 'The following benchmark files are created:' + bcolors.ENDC 
        if os.path.exists(self.output_filename_LK_bpo):
            print basename(self.output_filename_LK_bpo)
        if os.path.exists(self.output_filename_LK_cco):
            print basename(self.output_filename_LK_cco)
        if os.path.exists(self.output_filename_LK_mfo):
            print basename(self.output_filename_LK_mfo)
        if os.path.exists(self.output_filename_NK_bpo):
            print basename(self.output_filename_NK_bpo)
        if os.path.exists(self.output_filename_NK_cco):
            print basename(self.output_filename_NK_cco)
        if os.path.exists(self.output_filename_NK_mfo):
            print basename(self.output_filename_NK_mfo)
        print bcolors.OKGREEN + 'Thank you for using Benchmark Creation Tool' + bcolors.ENDC
        return None

    def process_data(self): # Process user data and create benchmark sets
        self.print_prolog() # Print the wellcome message and argument list
        fc.check_gaf_format(self.t1_input_file) # File format check for t1 file
        fc.check_gaf_format(self.t2_input_file) # File format check for t2 file
        self.create_intermediate_files() # Create necessary intermediate files
        cb.create_benchmarks(open(self.t1_iea_name, 'r'),
                             open(self.t1_exp_name, 'r'),
                             open(self.t2_exp_name, 'r'),
                             open(self.bmfile_LK_bpo, 'w'), 
                             open(self.bmfile_LK_cco, 'w'), 
                             open(self.bmfile_LK_mfo, 'w'), 
                             open(self.bmfile_NK_bpo, 'w'), 
                             open(self.bmfile_NK_cco, 'w'), 
                             open(self.bmfile_NK_mfo, 'w')) # Populate benchmark files
        self.remove_redundant_benchmarks() # Remove redundant benchmark entries
        self.delete_intermediate_files() # Delete intermediate files
        self.print_epilog() # Print summary of running this program
        return None

if __name__ == '__main__': 
    bm = Benchmark() # Create an instance of Benchmark class  
    bm.process_data() # Process data and create benchmark sets
